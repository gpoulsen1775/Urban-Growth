{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imports </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gpoulsen@apamail.org/Library/Python/3.10/lib/python/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> County Population Data </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper Functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropOutliers(df):\n",
    "\n",
    "    toRemove = [] #List of outliers to remove\n",
    "\n",
    "    yrs = df['Year'].unique() \n",
    "    g = df.groupby('Year') #Define groups for every year we'll examine\n",
    "\n",
    "    #Loop through groups\n",
    "    for y in yrs:\n",
    "\n",
    "        s = g.get_group(y)['Pop'] #Get Group\n",
    "\n",
    "        iq = s.describe().loc['75%'] - s.describe().loc['25%'] #Calculate the inner quartile\n",
    "        ub = s.describe().loc['75%'] + 1.5 * iq #Create Lower Bound considered outliers\n",
    "        lb = s.describe().loc['25%'] - 1.5 * iq #Creatre Uppper Bound considered outliers\n",
    "\n",
    "        toRemove.extend(list(s[~s.between(lb,ub)].index)) #Store outliers to remove later\n",
    "        df = df[~df.index.isin(toRemove)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def cleanFrame(df):\n",
    "\n",
    "    df['Pop'] = df['Pop'].astype(int) #Format response as int\n",
    "\n",
    "    df.drop(columns=['State','County']) #Drop Numeric Identifiers\n",
    "    df['County'] = df['Name'].str.split(\",\").str[0] #Split Name Column: County\n",
    "    df['State'] = df['Name'].str.split(\",\").str[1] #Split Name Column: State\n",
    "\n",
    "    df.index = df['State'] + \"-\" + df['County'] + \"-\" + df['Year'] #Set Unique Identifier\n",
    "    df = df.drop(columns='Name') #Drop Name Column\n",
    "\n",
    "    df = df[['County','State','Year','Pop']] #Reorder Columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Requesting County Populations from 2005 to 2021 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. num. of data pts. for each region 15.2995337995338\n"
     ]
    }
   ],
   "source": [
    "apiKey = 'fc8e94a76785a060f4aba9a659b4c84157f46dea' #I should omit this later\n",
    "\n",
    "cols = ['Name','Pop','State','County','Year'] #Labels for my df\n",
    "df = pd.DataFrame(columns=cols) #Create empty frame\n",
    "\n",
    "yrs = [*range(2005,2022)] #Consider all years\n",
    "yrs.remove(2020) #except for 2020 which was not released due to issues with Covid\n",
    "\n",
    "#Get All Available Years\n",
    "for y in yrs:\n",
    "\n",
    "    url = 'https://api.census.gov/data/' + str(y) + '/acs/acs1?get=NAME,B01001_001E&for=county:*&key=' + apiKey #URL for Query\n",
    "    response = requests.request(\"GET\",url) \n",
    "    \n",
    "    cLen = len(response.json()[1:]) \n",
    "    year = np.array([str(y) for x in range(cLen)]).reshape(cLen,1) #Create a year column for labeling our response\n",
    "\n",
    "    dt = np.array(response.json()[1:]) #Format response as np array\n",
    "    dt = np.hstack((dt,year)) #Add a year column to data\n",
    "    dt = pd.DataFrame(dt, columns=cols) #Format as a frame\n",
    "\n",
    "    df = pd.concat([df,dt],ignore_index=True) #Concatonate w/ our loaded data as of thus far\n",
    "\n",
    "print(\"Avg. num. of data pts. for each region \" + str(df['Name'].value_counts().mean())) #A rough summurative check on what we've loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Integration/Extracted Data/Population.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> County Migration Data </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper Functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processNewFormat(fn): #Helper function. We feed in the New files pathway and it returns tabularized data\n",
    "\n",
    "    df = pd.read_csv(fn,encoding='latin1') #Load in file\n",
    "    res = pd.DataFrame(columns=[\"State\",\"County\",\"Year\",\"Total Exemptions\"]) #Set Expected Dataframe\n",
    "\n",
    "    yr = fn.split('/')[-1] #Determine our year\n",
    "    yr = [x for x in yr if x.isdigit()]\n",
    "    yr = '20' + yr[0] + yr[1] + ' to 20' + yr[2] + yr[3]\n",
    "\n",
    "    # Rename so it's columns are accessable\n",
    "    cnt = 0\n",
    "    for c in df.columns:\n",
    "\n",
    "        df = df.rename(columns={c:cnt})\n",
    "        cnt += 1\n",
    "\n",
    "    df = df[ (df[2] == 96) & (df[3]==0)].reset_index(drop=True) #Filter down to summurative data\n",
    "\n",
    "    for idx, row in df.iterrows(): # Loop through frame\n",
    "\n",
    "        state = df.loc[idx,0] # Get State Code\n",
    "        county = df.loc[idx,1] # Get County Code\n",
    "        exemptTotal = df.loc[idx,7] #Get Exempt Totals\n",
    "\n",
    "        if('outflow' in fn): #Set negative if we are dealing with outflow\n",
    "\n",
    "            exemptTotal = -exemptTotal\n",
    "\n",
    "        res.loc[len(res)] = [state,county,yr,exemptTotal] #Append\n",
    "\n",
    "    return res\n",
    "\n",
    "def processOldFormat(fn): #Helper function. We feed in the old files pathway and it returns tabularized data\n",
    "\n",
    "    if(('0910' in fn) or ('1011' in fn)): #Format Varies by Year\n",
    "        df = pd.read_excel(fn,skiprows=5) # Read in data\n",
    "        # df = df[df[-1] != 'd']\n",
    "    else:\n",
    "        df = pd.read_excel(fn,skiprows=7,skipfooter=3) # Read in data\n",
    "        # df = df[df['Unnamed: 7'] != 'd'] #Get rid of missing data\n",
    "\n",
    "    res = pd.DataFrame(columns=[\"State\",\"County\",\"Year\",\"Total Exemptions\"]) #Set Expected Dataframe\n",
    "\n",
    "    yr = fn.split('/')[-1] #Determine our year\n",
    "    yr = [x for x in yr if x.isdigit()]\n",
    "    yr = '20' + yr[0] + yr[1] + ' to 20' + yr[2] + yr[3]\n",
    "\n",
    "    # Rename so it's columns are accessable\n",
    "    cnt = 0\n",
    "    for c in df.columns:\n",
    "\n",
    "        df = df.rename(columns={c:cnt})\n",
    "\n",
    "        if( (cnt != 4) & (cnt != 5) ): #Convert to numeric data if appropriate\n",
    "\n",
    "            df = df[~df[cnt].astype(str).str.contains('d')] #Drop Missing Data\n",
    "            df[cnt] = df[cnt].astype(int)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    df = df[ (df[2] == 96) & (df[3]==0)].reset_index(drop=True) #Filter down to summurative data\n",
    "\n",
    "    for idx, row in df[df.index > 0].iterrows(): # Loop through frame\n",
    "\n",
    "        state = df.loc[idx,0] # Get State Code\n",
    "        county = df.loc[idx,1] # Get County Code\n",
    "        exemptTotal = df.loc[idx,7] #Get Exempt Totals\n",
    "\n",
    "        if( (((yr == '2005 to 2006') | (yr == '2006 to 2007')) & ('o' == fn.split('/')[-1][8])) | (((yr != '2005 to 2006') & (yr != '2006 to 2007')) & ('o' == fn.split('/')[-1][6])) ): #Check posiitonal indicator for inflow vs outflow file for based on formats for each year\n",
    "\n",
    "            exemptTotal = -exemptTotal\n",
    "            \n",
    "        res.loc[len(res)] = [state,county,yr,exemptTotal]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extraction Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"State\",\"County\",\"Year\",\"Total Exemptions\"]) #Set Expected \n",
    "rd = '/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Extraction/Source Data/IRS Migration' # Root Directory\n",
    " \n",
    "for dir in os.listdir(rd): # Loop through root directory\n",
    "   \n",
    "    if(dir == \".DS_Store\"): # Skip if we hit .DS_Store\n",
    "        continue\n",
    "\n",
    "    cd = rd + \"/\" + dir #Get Child Directory\n",
    "\n",
    "    if('migration' in dir): #Handling the new format\n",
    "        \n",
    "        fnIn = [s for s in os.listdir(cd) if \"countyinflow\" in s][0] #Get Inflow filename\n",
    "        fnOut = [s for s in os.listdir(cd) if \"countyoutflow\" in s][0] #Get Outflow filename\n",
    "\n",
    "        df = pd.concat([df,processNewFormat(cd + \"/\" + fnIn)], ignore_index=True) #Process the In\n",
    "        df = pd.concat([df,processNewFormat(cd + \"/\" + fnOut)], ignore_index=True) #Process the Out\n",
    "\n",
    "    else: #Handling the old format\n",
    "\n",
    "        for fn in os.listdir(cd): #Loop through every inflow and outflow file\n",
    "\n",
    "            if(fn.split('.')[1] == 'xls'): #If excel process\n",
    "\n",
    "                df = pd.concat([df,processOldFormat(cd + \"/\" + fn)],ignore_index=True)\n",
    "\n",
    "df['Flow'] = 'In'\n",
    "df.loc[df['Total Exemptions'] < 0,'Flow']  = 'Out'\n",
    "df['County'] = df['County'].astype(str).str.zfill(3)\n",
    "df['State'] = df['State'].astype(str).str.zfill(2)\n",
    "df['Year'] = df['Year'].str.split(\" \").str[0]\n",
    "df.index = df['State'].astype(str) + df['County'].astype(str) + \"-\" + df['Year'] + \"-\" + df['Flow'] #Set index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Quick Meta-Analysis on Extraction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for Count of State-County-Year Records: \n",
      "2    0.998607\n",
      "1    0.001393\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution for Count of State-County-Year Records: \\n\"  + str(df[['State','County','Year']].value_counts().value_counts() / df[['State','County','Year']].value_counts().value_counts().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Ideally the distribution should be P(2) = 1, but P(2) approx. .999. We'll drop records that are missing an opposing flow record. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 94696\n",
      "Rows after dropping: 94630\n"
     ]
    }
   ],
   "source": [
    "sr = df[['State','County','Year']].value_counts() #Store series\n",
    "idx = list(sr[sr<2].index) #Split out index of those we need to filter out\n",
    "\n",
    "sts = [x[0] for x in idx]\n",
    "cnts = [x[1] for x in idx]\n",
    "yrs = [x[2] for x in idx]\n",
    "\n",
    "print(\"Rows before dropping: \" + str(len(df))) #We should lose 66 rows\n",
    "\n",
    "for i in range(len(sts)):\n",
    "\n",
    "    df = df[ (df['State'] != sts[i]) | (df['County'] != cnts[i]) | (df['Year'] != yrs[i])] #Filter our rows determined by idx seperated out\n",
    "\n",
    "#I'm certain there is a cleaner way to do this; I may circle back to this if time permits.\n",
    "\n",
    "print(\"Rows after dropping: \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2005    124030\n",
       "2006    132741\n",
       "2007    144342\n",
       "2008    134215\n",
       "2009    -14557\n",
       "2010    -18433\n",
       "2011    -60470\n",
       "2012     -1007\n",
       "2013    -19617\n",
       "2014     17235\n",
       "2015    -38692\n",
       "2016    -23693\n",
       "2017     51344\n",
       "2018     19521\n",
       "2019     18455\n",
       "Name: Total Exemptions, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Year')['Total Exemptions'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Domestic migration is a closed system, so net gains or losses are attributable to recorded foreign migration, which is reflected in the data set. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Transforming Datapoints into net migration values </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['State','County','Year'])['Total Exemptions'].sum().to_frame().reset_index() \n",
    "df.index = df['State'].astype(str) + df['County'].astype(str) + \"-\" + df['Year'] #Set index\n",
    "df = df.rename(columns={'Total Exemptions':'Net Migration'})\n",
    "df.to_parquet('/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Integration/Extracted Data/Migration.gzip',index=0) #Save the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> HPI Data </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper Functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHPI(df):\n",
    "\n",
    "    df = df[df['hpi_flavor'] == 'all-transactions'] #Look at all transactions\n",
    "    df = df[df['level'] == 'MSA'] #Look at Metropoliton Statistical Areas\n",
    "\n",
    "    df['city'] = df['place_name'].str.split(',').str[0]\n",
    "    df['state'] = df['place_name'].str.split(',').str[1].str.strip() #Split Out\n",
    "\n",
    "    df['city'] = df['city'].str.split('-').str[0] \n",
    "    df['state'] = df['state'].str[0:3] #Take the first city and state indicator for the region\n",
    "\n",
    "    df = df[['city','state','place_id','yr','period','index_nsa']] #Keep relevant fields\n",
    "    df = df.groupby(['city','state','place_id','yr'])['index_nsa'].mean().to_frame().reset_index() #Integrate quarterly indexes with a mean\n",
    "    df.loc[df['state'].str.len() > 2,'state'] = df[df['state'].str.len() > 2]['state'].str[0:2] # Clean out hyphens\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cleanConvertor(df):\n",
    "\n",
    "    df['county_fips'] = df['county_fips'].astype(str)\n",
    "    df['county_fips'] = df['county_fips'].apply(lambda x: '0' + x if len(x) < 5 else x)\n",
    "\n",
    "    df = df[['city','state_id','county_fips']]\n",
    "    df = df.rename(columns={'state_id':'state'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load & Clean </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Extraction/Source Data/HPI/HPI_master (1).csv')\n",
    "cnv = pd.read_csv('/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Extraction/Source Data/HPI/uscities.csv') #Load\n",
    "\n",
    "df = cleanHPI(df)\n",
    "cnv = cleanConvertor(cnv) #Clean\n",
    "\n",
    "df = df.merge(right=cnv,on=['city','state'],how='left') #Merge Data to get FIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Missing Analysis </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of locations with no attatched county:0.022277227722772276\n"
     ]
    }
   ],
   "source": [
    "ms = df[df['county_fips'].isnull()] #Get Nulls On Merge\n",
    "\n",
    "print(\"Percentage of locations with no attatched county:\" + str(len(ms[['city','state']].drop_duplicates()) / len(df[['city','state']].drop_duplicates())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Missing Quick Fix (I did this manually, as there were so few) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # Missing: 0\n"
     ]
    }
   ],
   "source": [
    "ms = ms[['city','state']].drop_duplicates().values #Get Nulls from Left Frame\n",
    "fpCds = [25001, 16001, 17097, 21111, 42091, 36059, 33015, 15003, 37067] #Fill w/ Looked uUp Values\n",
    "cnt = 0\n",
    "\n",
    "for rw in ms:\n",
    "\n",
    "    df.loc[(df['city'] == rw[0]) & (df['state'] == rw[1]),'county_fips'] = fpCds[cnt]\n",
    "    cnt+=1\n",
    "\n",
    "print(\"The # Missing: \" + str(len(df[df['county_fips'].isnull()]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yr\n",
       "1975     28.21250\n",
       "1976     33.40750\n",
       "1977     39.16000\n",
       "1978     45.64000\n",
       "1979     52.86500\n",
       "1980     56.59625\n",
       "1981     58.94500\n",
       "1982     59.14500\n",
       "1983     62.23750\n",
       "1984     64.77750\n",
       "1985     68.02000\n",
       "1986     72.57750\n",
       "1987     76.99750\n",
       "1988     79.45375\n",
       "1989     82.83250\n",
       "1990     85.47625\n",
       "1991     87.93500\n",
       "1992     91.40500\n",
       "1993     94.77500\n",
       "1994     98.46250\n",
       "1995    102.35125\n",
       "1996    105.98875\n",
       "1997    109.54875\n",
       "1998    114.23000\n",
       "1999    118.15125\n",
       "2000    123.15375\n",
       "2001    130.79750\n",
       "2002    136.56125\n",
       "2003    142.97750\n",
       "2004    152.51875\n",
       "2005    163.42250\n",
       "2006    175.54500\n",
       "2007    183.18625\n",
       "2008    182.73625\n",
       "2009    176.59250\n",
       "2010    169.14250\n",
       "2011    164.02375\n",
       "2012    163.80625\n",
       "2013    165.71500\n",
       "2014    171.97750\n",
       "2015    178.06500\n",
       "2016    185.74000\n",
       "2017    194.20250\n",
       "2018    204.77500\n",
       "2019    213.82750\n",
       "2020    224.91875\n",
       "2021    252.70750\n",
       "2022    292.30000\n",
       "Name: index_nsa, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('yr')['index_nsa'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['county_fips'] = df['county_fips'].astype(str) #Cast to str so that it can be saved in parquette\n",
    "df.index = df['county_fips'] + \"-\" + df['yr'].astype(str)\n",
    "df.to_parquet('/Users/gpoulsen@apamail.org/Desktop/Grant Training/Urban-Growth/Project/Integration/Extracted Data/Housing Index.gzip',index=0) #Save the data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
